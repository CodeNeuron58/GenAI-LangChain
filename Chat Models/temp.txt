// ============================================================================
// Why use the `temperature` parameter in LangChain when calling LLMs like GPT?
// ============================================================================
//
// üî• What is `temperature`?
//
// The `temperature` parameter controls the randomness or creativity of the AI‚Äôs responses.
// It scales the logits before sampling: lower values sharpen the distribution toward high‚Äëprobability tokens,
// while higher values flatten it, allowing less likely words to be chosen.:contentReference[oaicite:0]{index=0}
//
// Typical range is 0.0‚Äì1.0 (sometimes up to 2.0), though most APIs default to ~1.0.
//
// ----------------------------------------------------------------------------
//
// üö¶ How different temperature settings affect output:
//
// | Temperature   | Behavior             | Use Cases                                    |
// |---------------|----------------------|----------------------------------------------|
// | **0.0‚Äì0.2**   | Deterministic        | Factual Q&A, precise tasks, code             |
// | **0.3‚Äì0.6**   | Balanced             | General content, explanations, writing       |
// | **0.7‚Äì1.0**   | Creative             | Brainstorming, poetry, slogans, storytelling |
// | **>1.0**      | Highly random/chaotic| Experimental or novelty-driven tasks         |
//
// ---------------------------------------------------------------------------------------

// Example -
// | Temperature | Output                                            |
// | ----------- | ------------------------------------------------- |
// | 0.0         | "Fresh coffee, served daily."                     |
// | 0.7         | "Fuel your day with the perfect brew."            |
// | 1.0         | "Brewed with love, sipped with passion."          |
// | 1.5         | "Caffeine dreams roasted to reality‚Äîsip happens!" |

//
// üéØ Why use `temperature` in your model initialization:
//
// - It lets you **tailor output style**: lower for accuracy, higher for imagination.
// - Use low values for formats or structured tasks -> reliability.
// - Use higher values for creative generation or exploring different output variations.
//
// ----------------------------------------------------------------------------
//
// üîç LangChain-specific support:
//
// In LangChain you can pass `temperature` when you instantiate or configure a model:
```python
from langchain_openai import ChatOpenAI
llm = ChatOpenAI(temperature=0.7)




| Use Case                  | Recommended Temperature |
| ------------------------- | ----------------------- |
| Factual Q\&A              | `0.0 - 0.3`             |
| Customer support          | `0.2 - 0.5`             |
| Brainstorming ideas       | `0.7 - 1.0`             |
| Creative writing / poetry | `1.0 - 1.5`             |
| Code generation           | `0.1 - 0.3`             |




üß† Summary

    temperature controls randomness.

    Lower = focused, repetitive, safe.

    Higher = creative, diverse, risky.

    Use low temp for accuracy, high temp for imagination.
